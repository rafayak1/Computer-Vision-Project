{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkXhK2SXTAAi",
        "outputId": "748901b9-1f3b-4455-ef43-0be4ffac7808"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "import math\n",
        "import cvzone\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCel1bqjvRy1",
        "outputId": "c03e699f-bcf5-44b1-8487-963b3c1f2138"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1200, 512, 512, 3)"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "video_path = 'video.mp4'\n",
        "frames = list()\n",
        "\n",
        "# Load the video\n",
        "video = cv2.VideoCapture(video_path)\n",
        "\n",
        "while True:\n",
        "  # Read the next frame\n",
        "  ret, frame = video.read()\n",
        "  if not ret:\n",
        "    break\n",
        "\n",
        "  frame = cv2.resize(frame, (512, 512))\n",
        "  frames.append(frame)\n",
        "\n",
        "frames = np.array(frames)\n",
        "frames.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = YOLO(\"yolov8n.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SRzWlW75ScZ7",
        "outputId": "c7c7eba9-1e37-4d66-ab69-ee4a85f5fdb0"
      },
      "outputs": [],
      "source": [
        "# Load a model\n",
        "bbox_raw = list()\n",
        "\n",
        "for frame in frames:\n",
        "  results = model(frame)\n",
        "  for result in results:\n",
        "    boxes = result.boxes\n",
        "    for box in boxes:\n",
        "      conf = box.conf[0].item()\n",
        "      if conf >= 0.6:\n",
        "        x1, y1, x2, y2 = box.xyxy[0]\n",
        "        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
        "        w, h = x2-x1, y2-y1\n",
        "        cvzone.cornerRect(frame, (x1, y1, w, h))\n",
        "\n",
        "  bbox_raw.append(frame)\n",
        "\n",
        "bbox_raw = np.array(bbox_raw)\n",
        "bbox_raw.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def findHomography(img1, img2):\n",
        "    # Detect keypoints and descriptors in both images\n",
        "    sift = cv2.SIFT_create()\n",
        "    kp1, des1 = sift.detectAndCompute(img1, None)\n",
        "    kp2, des2 = sift.detectAndCompute(img2, None)\n",
        "\n",
        "    # Match features between the images\n",
        "    FLANN_INDEX_KDTREE = 1\n",
        "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
        "    search_params = dict(checks = 50)\n",
        "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
        "    matches = flann.knnMatch(des1, des2, k=2)\n",
        "\n",
        "    # Filter matches using Lowe's ratio test\n",
        "    good = []\n",
        "    for m,n in matches:\n",
        "        if m.distance < 0.7*n.distance:\n",
        "            good.append(m)\n",
        "\n",
        "    # Find homography using RANSAC\n",
        "    if len(good) > 4:\n",
        "        src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
        "        dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n",
        "\n",
        "        M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
        "        matchesMask = mask.ravel().tolist()\n",
        "    else:\n",
        "        M = None\n",
        "\n",
        "    return M\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "homography_matrix = np.array([[-3.68932364e-04, -3.98732829e-03,  9.84008439e-01],\n",
        "                     [-4.89824970e-05, -8.77735907e-04,  1.78061186e-01],\n",
        "                     [-9.99893210e-07, -8.96856626e-06,  2.19072220e-03]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "warpPerspective_list = list()\n",
        "for i in range(len(bbox_raw)):\n",
        "  M = findHomography(frames[0], frames[i])\n",
        "  if M is not None:\n",
        "    warped_img = cv2.warpPerspective(bbox_raw[i], M, (bbox_raw[i].shape[1], bbox_raw[i].shape[0]))\n",
        "  else:\n",
        "    warped_img = bbox_raw[i]\n",
        "  result = cv2.warpPerspective(warped_img, homography_matrix, (512, 512))\n",
        "  result = np.rot90(np.rot90(np.rot90(result)))\n",
        "  warpPerspective_list.append(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "warpPerspective_list = list()\n",
        "for i in bbox_raw:\n",
        "  result = cv2.warpPerspective(i, homography_matrix, (512, 512))\n",
        "  result = np.rot90(np.rot90(np.rot90(result)))\n",
        "  warpPerspective_list.append(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "OpenCV: FFMPEG: tag 0x58564944/'DIVX' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
            "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Video generated successfully!\n"
          ]
        }
      ],
      "source": [
        "output = cv2.VideoWriter('output3.mp4',cv2.VideoWriter_fourcc(*'DIVX'), 20, (512,512))\n",
        "for i in range(len(warpPerspective_list)):\n",
        "    output.write(warpPerspective_list[i])\n",
        "output.release()\n",
        "print(\"Video generated successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "OpenCV: FFMPEG: tag 0x58564944/'DIVX' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
            "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Video generated successfully!\n"
          ]
        }
      ],
      "source": [
        "output = cv2.VideoWriter('output2.mp4',cv2.VideoWriter_fourcc(*'DIVX'), 20, (512,512))\n",
        "for i in range(len(bbox_raw)):\n",
        "    output.write(bbox_raw[i])\n",
        "output.release()\n",
        "print(\"Video generated successfully!\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
